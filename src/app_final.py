# ==============================================================================
# APP HO√ÄN CH·ªàNH - Nh·∫≠n d·∫°ng ch·ªØ s·ªë & h√¨nh h·ªçc v·ªõi X·ª¨ L√ù ·∫¢NH N√ÇNG CAO
# ƒê·∫ßy ƒë·ªß t√≠nh nƒÉng cho BTL X·ª≠ l√Ω ·∫¢nh
# ==============================================================================

import streamlit as st
import cv2
import numpy as np
from tensorflow.keras.models import load_model
from PIL import Image
import pandas as pd
import matplotlib.pyplot as plt

# Import modules
from config import (
    DIGITS_LABELS, SHAPES_LABELS, 
    MODEL_PATH_DIGITS, MODEL_PATH_SHAPES
)
from scipy.ndimage import center_of_mass

# Import advanced modules
from preprocessing.visualizer import visualize_pipeline, display_pipeline_streamlit
from preprocessing.advanced import (contour_shape_analysis, compute_hu_moments,
                                   edge_detection_comparison, threshold_comparison)
from model_analysis.feature_maps import (display_feature_maps_streamlit, 
                                        display_filters_streamlit,
                                        display_heatmap_streamlit)
from shape_detection.polygon_detector import hybrid_shape_detection

# Canvas import
from streamlit_drawable_canvas import st_canvas

# ==============================================================================
# CONFIG
# ==============================================================================

st.set_page_config(
    page_title="BTL X·ª≠ L√Ω ·∫¢nh - Nh·∫≠n D·∫°ng",
    page_icon="üî¨",
    layout="wide"
)

# Custom CSS
st.markdown("""
<style>
    .main .block-container {
        padding-top: 1rem;
        max-width: 1400px;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    .stTabs [data-baseweb="tab"] {
        padding: 12px 24px;
        background-color: #f0f2f6;
        border-radius: 8px 8px 0 0;
    }
    .stButton button {
        font-weight: 600;
    }
</style>
""", unsafe_allow_html=True)

# ==============================================================================
# PREPROCESSING FUNCTION
# ==============================================================================

def smart_preprocess(image, mode='digit'):
    """Preprocessing th√¥ng minh cho c·∫£ digit v√† shape"""
    img = np.array(image)
    
    if len(img.shape) == 3:
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    else:
        gray = img
    
    h, w = gray.shape
    
    # üÜï T·ª± ƒë·ªông ph√°t hi·ªán n·ªÅn s√°ng (Paint/Upload) vs n·ªÅn t·ªëi (Canvas)
    mean_brightness = gray.mean()
    is_light_background = mean_brightness > 127
    
    if is_light_background:
        # N·ªÅn s√°ng (Paint): ƒê·∫£o ng∆∞·ª£c ƒë·ªÉ th√†nh n·ªÅn t·ªëi
        gray = 255 - gray
    
    # CLAHE
    clahe = cv2.createCLAHE(clipLimit=2.0 if mode == 'digit' else 3.0, 
                            tileGridSize=(8,8))
    enhanced = clahe.apply(gray)
    
    # Denoise
    if mode == 'shape':
        denoised = cv2.bilateralFilter(enhanced, 9, 75, 75)
    else:
        denoised = cv2.GaussianBlur(enhanced, (5, 5), 0)
    
    # Threshold
    blocksize = 11 if mode == 'digit' else 13
    c_value = 2 if mode == 'digit' else 3
    thresh = cv2.adaptiveThreshold(
        denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY_INV, blockSize=blocksize, C=c_value
    )
    
    # Morphology - Adaptive d·ª±a tr√™n ƒë·ªô d√†y n√©t
    kernel_size = 3 if mode == 'digit' else 5
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
    
    # Ph√°t hi·ªán ƒë·ªô d√†y n√©t: n√©t m·ªèng = √≠t pixel tr·∫Øng
    white_ratio = np.sum(thresh > 0) / thresh.size
    
    if white_ratio < 0.20:  # N√©t m·ªèng (< 20% di·ªán t√≠ch) - TƒÇNG t·ª´ 15% ƒë·ªÉ b·∫£o v·ªá t·ªët h∆°n
        # Morphology nh·∫π: ch·ªâ close, kh√¥ng open (gi·ªØ n√©t m·ªèng)
        closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=1)
        cleaned = closed  # B·ªè qua OPEN ƒë·ªÉ kh√¥ng m·∫•t n√©t
    else:  # N√©t d√†y/b√¨nh th∆∞·ªùng - ƒëa s·ªë tr∆∞·ªùng h·ª£p
        # Morphology ƒë·∫ßy ƒë·ªß: close + open (lo·∫°i nhi·ªÖu t·ªët)
        closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=1)
        cleaned = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel, iterations=1)
    
    # Find contours
    contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if contours:
        # L·ªçc contours c√≥ di·ªán t√≠ch ƒë·ªß l·ªõn (lo·∫°i nhi·ªÖu nh·ªè)
        min_area = (h * w) * 0.01  # √çt nh·∫•t 1% di·ªán t√≠ch ·∫£nh
        valid_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_area]
        
        if valid_contours:
            # N·∫øu c√≥ nhi·ªÅu contours l·ªõn (nh∆∞ s·ªë 8 b·ªã t√°ch), ki·ªÉm tra kho·∫£ng c√°ch
            if len(valid_contours) > 1:
                # T√≠nh bounding boxes c·ªßa t·ª´ng contour
                bboxes = [cv2.boundingRect(cnt) for cnt in valid_contours]
                
                # Ki·ªÉm tra xem c√°c contours c√≥ g·∫ßn nhau kh√¥ng (< 40% chi·ªÅu r·ªông/cao ·∫£nh)
                max_distance = max(h, w) * 0.4
                should_merge = False
                
                for i in range(len(bboxes)):
                    for j in range(i+1, len(bboxes)):
                        x1, y1, w1, h1 = bboxes[i]
                        x2, y2, w2, h2 = bboxes[j]
                        
                        # Kho·∫£ng c√°ch gi·ªØa 2 centers
                        cx1, cy1 = x1 + w1//2, y1 + h1//2
                        cx2, cy2 = x2 + w2//2, y2 + h2//2
                        distance = np.sqrt((cx1-cx2)**2 + (cy1-cy2)**2)
                        
                        if distance < max_distance:
                            should_merge = True
                            break
                    if should_merge:
                        break
                
                if should_merge:
                    # Merge c√°c contours g·∫ßn nhau (s·ªë 8, 6, 9, 0)
                    all_points = np.vstack(valid_contours)
                    x, y, cw, ch = cv2.boundingRect(all_points)
                else:
                    # C√°c contours xa nhau ‚Üí ch·ªçn l·ªõn nh·∫•t (tr√°nh nhi·ªÖu)
                    largest = max(valid_contours, key=cv2.contourArea)
                    x, y, cw, ch = cv2.boundingRect(largest)
            else:
                # Ch·ªâ 1 contour - ch·ªçn n√≥
                x, y, cw, ch = cv2.boundingRect(valid_contours[0])
            
            padding = 15 if mode == 'digit' else 20
            x1 = max(0, x - padding)
            y1 = max(0, y - padding)
            x2 = min(w, x + cw + padding)
            y2 = min(h, y + ch + padding)
            cropped = cleaned[y1:y2, x1:x2]
        else:
            cropped = cleaned
    else:
        cropped = cleaned
    
    # Resize
    if cropped.size > 0 and cropped.shape[0] > 0 and cropped.shape[1] > 0:
        resized = cv2.resize(cropped, (20, 20), interpolation=cv2.INTER_AREA)
    else:
        resized = np.zeros((20, 20), dtype=np.uint8)
    
    # Pad
    padded = np.pad(resized, ((4,4),(4,4)), 'constant', constant_values=0)
    
    # Center
    if np.sum(padded) > 0:
        cy, cx = center_of_mass(padded)
        shiftx = int(np.round(14 - cx))
        shifty = int(np.round(14 - cy))
        M = np.float32([[1, 0, shiftx], [0, 1, shifty]])
        centered = cv2.warpAffine(padded, M, (28, 28))
    else:
        centered = padded
    
    normalized = centered.astype(np.float32) / 255.0
    
    return {
        'original': img,
        'gray': gray,
        'enhanced': enhanced,
        'thresh': thresh,
        'cleaned': cleaned,
        'cropped': cropped,
        'final': centered,
        'processed': normalized.reshape(1, 28, 28, 1)
    }

# ==============================================================================
# LOAD MODELS
# ==============================================================================

@st.cache_resource
def load_digit_model():
    try:
        model = load_model(MODEL_PATH_DIGITS)
        return model, True
    except Exception as e:
        return None, False

@st.cache_resource
def load_shape_model():
    try:
        model = load_model(MODEL_PATH_SHAPES)
        return model, True
    except Exception as e:
        return None, False

digit_model, DIGIT_MODEL_LOADED = load_digit_model()
shape_model, SHAPE_MODEL_LOADED = load_shape_model()

# ==============================================================================
# SESSION STATE
# ==============================================================================

if 'recognition_mode' not in st.session_state:
    st.session_state.recognition_mode = 'Nh·∫≠n d·∫°ng S·ªë'
if 'uploaded_files' not in st.session_state:
    st.session_state.uploaded_files = []
if 'last_results' not in st.session_state:
    st.session_state.last_results = []
if 'show_results' not in st.session_state:
    st.session_state.show_results = False
if 'current_image_for_analysis' not in st.session_state:
    st.session_state.current_image_for_analysis = None

# ==============================================================================
# HEADER
# ==============================================================================

st.markdown("""
<div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 24px; border-radius: 12px; margin-bottom: 20px;'>
    <h1 style='color: white; margin: 0; font-size: 32px;'>
        üî¨ BTL X·ª¨ L√ù ·∫¢NH - Nh·∫≠n D·∫°ng Ch·ªØ S·ªë & H√¨nh H·ªçc
    </h1>
    <p style='color: #f0f0f0; margin: 8px 0 0 0; font-size: 15px;'>
        ‚ú® Visualization Pipeline ‚Ä¢ Feature Maps ‚Ä¢ Shape Detection ‚Ä¢ Advanced CV Techniques
    </p>
</div>
""", unsafe_allow_html=True)

# ==============================================================================
# MAIN TABS
# ==============================================================================

tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "üéØ Nh·∫≠n D·∫°ng", 
    "üî¨ Pipeline X·ª≠ L√Ω ·∫¢nh",
    "üß† Feature Maps (CNN)",
    "üîç Shape Analysis (OpenCV)",
    "üìö K·ªπ Thu·∫≠t N√¢ng Cao"
])

# ==============================================================================
# TAB 1: NH·∫¨N D·∫†NG
# ==============================================================================

with tab1:
    st.markdown("### Nh·∫≠n D·∫°ng T·ª± ƒê·ªông")
    
    # Mode selection
    col_m1, col_m2 = st.columns(2)
    with col_m1:
        if st.button("üî¢ Nh·∫≠n d·∫°ng S·ªê (0-9)", 
                     type="primary" if st.session_state.recognition_mode == 'Nh·∫≠n d·∫°ng S·ªë' else "secondary",
                     use_container_width=True):
            st.session_state.recognition_mode = 'Nh·∫≠n d·∫°ng S·ªë'
            st.rerun()
    
    with col_m2:
        if st.button("üî∫ Nh·∫≠n d·∫°ng H√åNH H·ªåC", 
                     type="primary" if st.session_state.recognition_mode == 'Nh·∫≠n d·∫°ng H√¨nh h·ªçc' else "secondary",
                     use_container_width=True):
            st.session_state.recognition_mode = 'Nh·∫≠n d·∫°ng H√¨nh h·ªçc'
            st.rerun()
    
    # Display mode
    if st.session_state.recognition_mode == 'Nh·∫≠n d·∫°ng S·ªë':
        st.info("üî¢ **Ch·∫ø ƒë·ªô:** Nh·∫≠n d·∫°ng s·ªë 0-9 | Model chuy√™n bi·ªát cho digits")
        current_model = digit_model
        model_loaded = DIGIT_MODEL_LOADED
        current_labels = DIGITS_LABELS
        preprocess_mode = 'digit'
    else:
        st.info("üî∫ **Ch·∫ø ƒë·ªô:** Nh·∫≠n d·∫°ng h√¨nh h·ªçc (Tr√≤n/HCN/Tam gi√°c) | Model chuy√™n bi·ªát cho shapes")
        current_model = shape_model
        model_loaded = SHAPE_MODEL_LOADED
        current_labels = SHAPES_LABELS
        preprocess_mode = 'shape'
    
    st.markdown("---")
    
    # Input method selection
    st.markdown("### Ph∆∞∆°ng th·ª©c nh·∫≠p ·∫£nh")
    input_method = st.radio(
        "Ch·ªçn c√°ch nh·∫≠p:",
        ["Upload ·∫£nh", "V·∫Ω tr·ª±c ti·∫øp"],
        horizontal=True
    )
    
    uploaded_file = None
    canvas_result = None
    
    if input_method == "Upload ·∫£nh":
        uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh ƒë·ªÉ nh·∫≠n d·∫°ng", type=['png', 'jpg', 'jpeg'])
    else:
        st.markdown("**V·∫Ω ch·ªØ s·ªë ho·∫∑c h√¨nh h·ªçc:**")
        
        # Ch·ªçn m√†u b√∫t v√† ƒë·ªô d√†y
        col_color1, col_color2, col_color3 = st.columns([1, 1, 2])
        with col_color1:
            stroke_color = st.color_picker("M√†u m·ª±c:", "#00FF00", key="stroke_color")
        with col_color2:
            stroke_width = st.slider("ƒê·ªô d√†y n√©t:", 5, 30, 15, key="stroke_width")
        
        col_canvas1, col_canvas2 = st.columns([2, 1])
        
        with col_canvas1:
            # Drawing canvas
            canvas_result = st_canvas(
                fill_color="rgba(0, 0, 0, 0)",
                stroke_width=stroke_width,
                stroke_color=stroke_color,
                background_color="#000000",
                height=280,
                width=280,
                drawing_mode="freedraw",
                key="canvas",
            )
        
        with col_canvas2:
            st.markdown("**üí° M·∫πo v·∫Ω t·ªët:**")
            if st.session_state.recognition_mode == 'Nh·∫≠n d·∫°ng S·ªë':
                st.write("‚Ä¢ V·∫Ω ch·ªØ s·ªë 0-9")
                st.write("‚Ä¢ ƒê·ªô d√†y n√©t ‚â• 8px")
                st.write("‚Ä¢ V·∫Ω ƒë·ªß l·ªõn, r√µ r√†ng")
                st.write("‚Ä¢ Th·∫≥ng ƒë·ª©ng (kh√¥ng xoay qu√° 20¬∞)")
            else:
                st.write("‚Ä¢ Tr√≤n / Ch·ªØ nh·∫≠t / Tam gi√°c")
                st.write("‚Ä¢ ƒê·ªô d√†y n√©t ‚â• 8px")
                st.write("‚Ä¢ C√≥ th·ªÉ v·∫Ω ·ªü b·∫•t k·ª≥ g√≥c ƒë·ªô")
            
            if st.button("X√≥a canvas", use_container_width=True):
                st.rerun()
    
    # Process input
    image = None
    
    if input_method == "Upload ·∫£nh" and uploaded_file:
        image = Image.open(uploaded_file)
    elif input_method == "V·∫Ω tr·ª±c ti·∫øp" and canvas_result.image_data is not None:
        # Convert canvas to PIL Image (extract RGB, not alpha)
        canvas_data = canvas_result.image_data
        if np.sum(canvas_data) > 0:  # Check if drawn
            # Get RGB channels (colored strokes on black background)
            rgb_image = canvas_data[:, :, :3]
            
            # Store original RGB for display
            st.session_state['canvas_rgb'] = rgb_image.copy()
            
            # Convert to grayscale (this is the preprocessing step!)
            gray_canvas = cv2.cvtColor(rgb_image.astype('uint8'), cv2.COLOR_RGB2GRAY)
            
            # Store grayscale for display
            st.session_state['canvas_gray'] = gray_canvas.copy()
            
            # Create PIL Image
            image = Image.fromarray(gray_canvas)
    
    if image:
        
        col1, col2, col3 = st.columns([1, 1, 1])
        
        with col1:
            # Hi·ªÉn th·ªã ·∫£nh RGB n·∫øu t·ª´ canvas, grayscale n·∫øu upload
            if input_method == "V·∫Ω tr·ª±c ti·∫øp" and 'canvas_rgb' in st.session_state:
                st.image(st.session_state['canvas_rgb'], caption="·∫¢nh g·ªëc (RGB)", use_container_width=True)
            else:
                st.image(image, caption="·∫¢nh g·ªëc", use_container_width=True, channels='GRAY')
        
        if st.button("NH·∫¨N D·∫†NG", type="primary", use_container_width=True):
            if not model_loaded:
                st.error(f"‚úó Model ch∆∞a train! Ch·∫°y: `python train_{'digits' if preprocess_mode=='digit' else 'shapes'}.py`")
            else:
                with st.spinner("ƒêang x·ª≠ l√Ω..."):
                    # Preprocess
                    processed = smart_preprocess(image, mode=preprocess_mode)
                    
                    # Predict
                    predictions = current_model.predict(processed['processed'], verbose=0)
                    pred_class = np.argmax(predictions[0])
                    confidence = predictions[0][pred_class] * 100
                    
                    # Save for other tabs (with RGB original if from canvas)
                    original_for_display = image
                    if input_method == "V·∫Ω tr·ª±c ti·∫øp" and 'canvas_rgb' in st.session_state:
                        # Use RGB canvas for pipeline display
                        original_for_display = Image.fromarray(st.session_state['canvas_rgb'])
                    
                    st.session_state.current_image_for_analysis = {
                        'original': original_for_display,
                        'processed': processed,
                        'prediction': pred_class,
                        'confidence': confidence,
                        'all_probs': predictions[0],
                        'mode': preprocess_mode
                    }
                    
                    with col2:
                        st.image(processed['final'], caption="X·ª≠ l√Ω 28x28", use_container_width=True, channels='GRAY')
                    
                    with col3:
                        result_label = current_labels[pred_class]
                        color = '#4caf50' if confidence >= 90 else '#ff9800' if confidence >= 75 else '#f44336'
                        
                        st.markdown(f"""
                        <div style='background: {color}20; padding: 24px; border-radius: 12px; 
                                    border-left: 5px solid {color}; text-align: center;'>
                            <h2 style='color: {color}; margin: 0;'>{result_label}</h2>
                            <p style='color: {color}; font-size: 20px; margin: 10px 0 0 0;'>
                                Confidence: {confidence:.1f}%
                            </p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # Top predictions
                    st.markdown("#### üìä Top 3 Predictions")
                    top3_idx = np.argsort(predictions[0])[::-1][:3]
                    
                    cols = st.columns(3)
                    for i, idx in enumerate(top3_idx):
                        with cols[i]:
                            prob = predictions[0][idx] * 100
                            st.metric(
                                f"#{i+1}: {current_labels[idx]}", 
                                f"{prob:.1f}%",
                                delta=f"{'‚úì' if i == 0 else ''}"
                            )
                
                st.success("‚úÖ Nh·∫≠n d·∫°ng ho√†n t·∫•t! Xem c√°c tab kh√°c ƒë·ªÉ ph√¢n t√≠ch chi ti·∫øt.")

# ==============================================================================
# TAB 2: PIPELINE X·ª¨ L√ù ·∫¢NH
# ==============================================================================

with tab2:
    st.markdown("### Pipeline X·ª≠ L√Ω ·∫¢nh (10 B∆∞·ªõc)")
    
    if st.session_state.current_image_for_analysis:
        data = st.session_state.current_image_for_analysis
        
        # Visualize full pipeline
        result = visualize_pipeline(data['original'], mode=data['mode'])
        display_pipeline_streamlit(result)
        
        # Additional analysis
        st.markdown("---")
        st.markdown("### üìä Ph√¢n T√≠ch Histogram")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Histogram ·∫¢nh G·ªëc**")
            gray_img = data['processed']['gray']
            fig1, ax1 = plt.subplots(figsize=(8, 4))
            ax1.hist(gray_img.ravel(), bins=256, range=[0, 256], color='blue', alpha=0.7)
            ax1.set_xlabel('Pixel Intensity')
            ax1.set_ylabel('Frequency')
            ax1.grid(alpha=0.3)
            st.pyplot(fig1)
        
        with col2:
            st.markdown("**Histogram Sau CLAHE**")
            enhanced_img = data['processed']['enhanced']
            fig2, ax2 = plt.subplots(figsize=(8, 4))
            ax2.hist(enhanced_img.ravel(), bins=256, range=[0, 256], color='green', alpha=0.7)
            ax2.set_xlabel('Pixel Intensity')
            ax2.set_ylabel('Frequency')
            ax2.grid(alpha=0.3)
            st.pyplot(fig2)
        
        st.caption("üìà CLAHE l√†m histogram ph√¢n b·ªë ƒë·ªÅu h∆°n ‚Üí TƒÉng contrast, d·ªÖ threshold")
        
    else:
        st.warning("‚ö†Ô∏è Vui l√≤ng upload v√† nh·∫≠n d·∫°ng ·∫£nh ·ªü Tab 1 tr∆∞·ªõc!")

# ==============================================================================
# TAB 3: FEATURE MAPS
# ==============================================================================

with tab3:
    st.markdown("### Feature Maps - Tr·ª±c Quan H√≥a CNN")
    
    if st.session_state.current_image_for_analysis:
        data = st.session_state.current_image_for_analysis
        model = digit_model if data['mode'] == 'digit' else shape_model
        
        if model:
            # Feature Maps
            st.markdown("#### Activation Maps - Output c·ªßa t·ª´ng Conv Layer")
            display_feature_maps_streamlit(model, data['processed']['processed'], max_per_layer=8)
            
            st.markdown("---")
            
            # Filters
            st.markdown("#### Filters/Kernels - B·ªô l·ªçc CNN h·ªçc ƒë∆∞·ª£c")
            display_filters_streamlit(model, max_per_layer=16)
            
            st.markdown("---")
            
            # Heatmap
            st.markdown("#### Attention Heatmap (Class Activation Map)")
            display_heatmap_streamlit(
                model, 
                data['processed']['processed'],
                data['prediction'],
                data['processed']['final']
            )
        else:
            st.error("Model ch∆∞a load!")
    else:
        st.warning("‚ö†Ô∏è Vui l√≤ng upload v√† nh·∫≠n d·∫°ng ·∫£nh ·ªü Tab 1 tr∆∞·ªõc!")

# ==============================================================================
# TAB 4: SHAPE ANALYSIS
# ==============================================================================

with tab4:
    st.markdown("### Shape Detection - Ph√°t Hi·ªán H√¨nh H·ªçc")
    
    if st.session_state.current_image_for_analysis:
        data = st.session_state.current_image_for_analysis
        
        # Hybrid detection
        st.markdown("#### Ph√°t Hi·ªán T·ª± ƒê·ªông (Hybrid Method)")
        
        gray_img = data['processed']['gray']
        result = hybrid_shape_detection(gray_img)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.image(gray_img, caption="·∫¢nh g·ªëc (grayscale)", use_container_width=True, channels='GRAY')
        
        with col2:
            if result['visualization'] is not None:
                st.image(result['visualization'], caption="Ph√°t hi·ªán shape", use_container_width=True, channels='RGB')
        
        # Summary
        st.markdown("#### üìä K·∫øt Qu·∫£ Ph√°t Hi·ªán")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Dominant Shape", result['dominant_shape'])
        with col2:
            st.metric("Circles", result['summary']['n_circles'])
        with col3:
            st.metric("Rectangles", result['summary']['n_rectangles'])
        with col4:
            st.metric("Triangles", result['summary']['n_triangles'])
        
        # Detailed analysis
        st.markdown("---")
        st.markdown("#### üî¨ Ph√¢n T√≠ch Chi Ti·∫øt Contour")
        
        analysis = contour_shape_analysis(gray_img)
        
        if analysis:
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Area", f"{analysis['area']:.0f} px¬≤")
                st.metric("Perimeter", f"{analysis['perimeter']:.0f} px")
            
            with col2:
                st.metric("Circularity", f"{analysis['circularity']:.3f}")
                st.metric("Solidity", f"{analysis['solidity']:.3f}")
            
            with col3:
                st.metric("Aspect Ratio", f"{analysis['aspect_ratio']:.2f}")
                st.metric("Vertices", analysis['num_vertices'])
            
            st.success(f"**K·∫øt lu·∫≠n:** {analysis['shape_type']}")
            
            # Hu Moments
            st.markdown("#### Hu Moments (ƒê·∫∑c tr∆∞ng b·∫•t bi·∫øn)")
            hu = compute_hu_moments(gray_img)
            
            hu_df = pd.DataFrame({
                'Moment': [f'Hu[{i}]' for i in range(7)],
                'Value': [f"{val:.4f}" for val in hu]
            })
            
            st.dataframe(hu_df, use_container_width=True, hide_index=True)
            st.caption("üìå Hu Moments b·∫•t bi·∫øn v·ªõi translation, rotation, scale - D√πng ƒë·ªÉ nh·∫≠n d·∫°ng shape")
        
    else:
        st.warning("‚ö†Ô∏è Vui l√≤ng upload v√† nh·∫≠n d·∫°ng ·∫£nh ·ªü Tab 1 tr∆∞·ªõc!")

# ==============================================================================
# TAB 5: K·ª∏ THU·∫¨T N√ÇNG CAO
# ==============================================================================

with tab5:
    st.markdown("### So S√°nh & Ph√¢n T√≠ch K·ªπ Thu·∫≠t")
    
    # Ph·∫ßn 1: K·ªπ thu·∫≠t ƒê√É √ÅP D·ª§NG trong h·ªá th·ªëng
    st.markdown("#### T·ªïng h·ª£p k·ªπ thu·∫≠t ƒë√£ √°p d·ª•ng")
    
    applied_techniques = pd.DataFrame({
        'STT': range(1, 11),
        'K·ªπ Thu·∫≠t': [
            'CLAHE (Contrast Limited AHE)',
            'Adaptive Threshold (Gaussian)',
            'Bilateral Filter / Gaussian Blur',
            'Morphology Operations (CLOSE/OPEN)',
            'Contour Detection (RETR_EXTERNAL)',
            'Bounding Box & Crop',
            'Center of Mass Alignment',
            'Distance Transform',
            'Hu Moments',
            'CNN Feature Extraction'
        ],
        '√Åp d·ª•ng t·∫°i': [
            'B∆∞·ªõc 2 - Pipeline',
            'B∆∞·ªõc 4 - Pipeline',
            'B∆∞·ªõc 3 - Pipeline',
            'B∆∞·ªõc 5 - Pipeline',
            'B∆∞·ªõc 6 - Pipeline',
            'B∆∞·ªõc 7 - Pipeline',
            'B∆∞·ªõc 9 - Pipeline',
            'Tab 4 - Shape Detection',
            'Tab 4 - Shape Detection',
            'Tab 3 - Feature Maps'
        ]
    })
    
    st.dataframe(applied_techniques, use_container_width=True, hide_index=True)
    
    st.markdown("---")
    
    # Ph·∫ßn 2: SO S√ÅNH CHI TI·∫æT V√Ä PH√ÇN T√çCH
    st.markdown("#### So s√°nh chi ti·∫øt c√°c ph∆∞∆°ng ph√°p")
    
    if st.session_state.current_image_for_analysis:
        data = st.session_state.current_image_for_analysis
        gray_img = data['processed']['gray']
        binary_img = data['processed']['cleaned']  # ·∫¢nh sau morphology
        
        # =================================================================
        # 1. THRESHOLD COMPARISON (QUAN TR·ªåNG NH·∫§T)
        # =================================================================
        st.markdown("**1. Ph∆∞∆°ng ph√°p Threshold - T·∫°i sao ch·ªçn Adaptive Gaussian?**")
        
        thresholds = threshold_comparison(gray_img)
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.image(thresholds['otsu'], caption="Otsu (Global)", use_container_width=True, channels='GRAY')
        with col2:
            st.image(thresholds['adaptive_mean'], caption="Adaptive Mean", use_container_width=True, channels='GRAY')
        with col3:
            st.image(thresholds['adaptive_gaussian'], caption="Adaptive Gaussian", use_container_width=True, channels='GRAY')
        with col4:
            st.image(thresholds['binary_fixed'], caption="Binary (threshold=127)", use_container_width=True, channels='GRAY')
        
        # Ph√¢n t√≠ch chi ti·∫øt
        st.markdown("**Ph√¢n t√≠ch so s√°nh:**")
        
        comparison_df = pd.DataFrame({
            'Ph∆∞∆°ng ph√°p': ['Otsu (Global)', 'Binary Fixed', 'Adaptive Mean', 'Adaptive Gaussian (‚úì ƒê√£ ch·ªçn)'],
            '∆Øu ƒëi·ªÉm': [
                'T·ª± ƒë·ªông t√¨m ng∆∞·ª°ng t·ªëi ∆∞u to√†n c·ª•c',
                'ƒê∆°n gi·∫£n, nhanh nh·∫•t',
                'Th√≠ch nghi v·ªõi t·ª´ng v√πng c·ª•c b·ªô',
                'Th√≠ch nghi c·ª•c b·ªô + Smoothing Gaussian'
            ],
            'Nh∆∞·ª£c ƒëi·ªÉm': [
                'Th·∫•t b·∫°i v·ªõi ·∫£nh √°nh s√°ng kh√¥ng ƒë·ªÅu',
                'Kh√¥ng linh ho·∫°t, ph·ª• thu·ªôc ng∆∞·ª°ng c·ªë ƒë·ªãnh',
                'Nh·∫°y nhi·ªÖu, d·ªÖ t·∫°o "salt-pepper"',
                'Ch·∫≠m h∆°n Global, c·∫ßn tune blockSize'
            ],
            'Ph√π h·ª£p': [
                '·∫¢nh ƒë·ªìng nh·∫•t, √°nh s√°ng ƒë·ªÅu',
                '·∫¢nh binary r√µ r√†ng',
                '·∫¢nh c√≥ v√πng t·ªëi/s√°ng kh√°c nhau',
                '·∫¢nh vi·∫øt tay, √°nh s√°ng kh√¥ng ƒë·ªÅu (‚úì)'
            ]
        })
        
        st.dataframe(comparison_df, use_container_width=True, hide_index=True)
        
        st.success("**K·∫øt lu·∫≠n:** Ch·ªçn **Adaptive Gaussian** v√¨ ·∫£nh input (vi·∫øt tay/v·∫Ω) th∆∞·ªùng c√≥ √°nh s√°ng kh√¥ng ƒë·ªÅu, b√≥ng ƒë·ªï. Gaussian smoothing gi·∫£m nhi·ªÖu t·ªët h∆°n Mean.")
        
        st.markdown("---")
        
        # =================================================================
        # 2. EDGE DETECTION vs CONTOUR DETECTION
        # =================================================================
        st.markdown("**2. Edge Detection vs Contour Detection - T·∫°i sao ch·ªçn Contour?**")
        
        edges = edge_detection_comparison(gray_img)
        
        # Th√™m c·ªôt Contour Detection (ƒëang d√πng)
        contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        contour_img = np.zeros_like(binary_img)
        cv2.drawContours(contour_img, contours, -1, 255, 2)
        
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            st.image(edges['sobel'], caption="Sobel", use_container_width=True, channels='GRAY')
        with col2:
            st.image(edges['canny'], caption="Canny", use_container_width=True, channels='GRAY')
        with col3:
            st.image(edges['laplacian'], caption="Laplacian", use_container_width=True, channels='GRAY')
        with col4:
            st.image(edges['scharr'], caption="Scharr", use_container_width=True, channels='GRAY')
        with col5:
            st.image(contour_img, caption="Contour (‚úì ƒêang d√πng)", use_container_width=True, channels='GRAY')
        
        # Ph√¢n t√≠ch chi ti·∫øt
        st.markdown("**Ph√¢n t√≠ch so s√°nh:**")
        
        edge_comparison_df = pd.DataFrame({
            'Ph∆∞∆°ng ph√°p': ['Sobel', 'Canny', 'Laplacian', 'Scharr', 'Contour (‚úì ƒê√£ ch·ªçn)'],
            'Lo·∫°i': ['Gradient', 'Multi-stage', 'Second derivative', 'Gradient', 'Topology-based'],
            'Output': ['Edge pixels', 'Edge pixels', 'Edge pixels', 'Edge pixels', 'Closed curves (polygons)'],
            '∆Øu ƒëi·ªÉm': [
                'ƒê∆°n gi·∫£n, ph√°t hi·ªán nhanh',
                'Edge m·ªèng, r√µ r√†ng nh·∫•t',
                'Nh·∫°y v·ªõi noise, ph√°t hi·ªán g√≥c',
                'Ch√≠nh x√°c h∆°n Sobel (kernel l·ªõn)',
                'Cho bounding box, area, perimeter'
            ],
            'Nh∆∞·ª£c ƒëi·ªÉm': [
                'Edge d√†y, nhi·ªÖu',
                'Ph·ª©c t·∫°p, c·∫ßn 2 threshold',
                'R·∫•t nh·∫°y nhi·ªÖu, edge k√©p',
                'T√≠nh to√°n ch·∫≠m h∆°n',
                'C·∫ßn ·∫£nh binary s·∫°ch tr∆∞·ªõc'
            ],
            'Ph√π h·ª£p': [
                'Ph√°t hi·ªán bi√™n nhanh',
                '·∫¢nh ch·∫•t l∆∞·ª£ng cao, √≠t nhi·ªÖu',
                'Ph√°t hi·ªán g√≥c, ƒëi·ªÉm ƒë·∫∑c bi·ªát',
                'C·∫ßn ƒë·ªô ch√≠nh x√°c cao',
                'Ph√¢n t√≠ch h√¨nh h·ªçc, t√≠nh to√°n ƒë·∫∑c tr∆∞ng (‚úì)'
            ]
        })
        
        st.dataframe(edge_comparison_df, use_container_width=True, hide_index=True)
        
        st.success("**K·∫øt lu·∫≠n:** Ch·ªçn **Contour Detection** v√¨ c·∫ßn tr√≠ch xu·∫•t **bounding box, area, perimeter** ƒë·ªÉ crop & resize ƒë·ªëi t∆∞·ª£ng. Edge detection ch·ªâ cho pixels r·ªùi r·∫°c, kh√¥ng th·ªÉ t√≠nh to√°n ƒë·∫∑c tr∆∞ng h√¨nh h·ªçc.")
        
        st.markdown("---")
        
        # =================================================================
        # 3. MORPHOLOGY PARAMETERS
        # =================================================================
        st.markdown("**3. Morphology Operations - T·∫°i sao iterations=1, kernel=3x3?**")
        
        # Test v·ªõi c√°c config kh√°c nhau
        kernel_3 = np.ones((3, 3), np.uint8)
        kernel_5 = np.ones((5, 5), np.uint8)
        
        morph_1_3 = cv2.morphologyEx(binary_img, cv2.MORPH_CLOSE, kernel_3, iterations=1)
        morph_2_3 = cv2.morphologyEx(binary_img, cv2.MORPH_CLOSE, kernel_3, iterations=2)
        morph_1_5 = cv2.morphologyEx(binary_img, cv2.MORPH_CLOSE, kernel_5, iterations=1)
        morph_2_5 = cv2.morphologyEx(binary_img, cv2.MORPH_CLOSE, kernel_5, iterations=2)
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.image(morph_1_3, caption="iter=1, kernel=3x3 (‚úì)", use_container_width=True, channels='GRAY')
        with col2:
            st.image(morph_2_3, caption="iter=2, kernel=3x3", use_container_width=True, channels='GRAY')
        with col3:
            st.image(morph_1_5, caption="iter=1, kernel=5x5", use_container_width=True, channels='GRAY')
        with col4:
            st.image(morph_2_5, caption="iter=2, kernel=5x5", use_container_width=True, channels='GRAY')
        
        # Ph√¢n t√≠ch
        st.markdown("**Ph√¢n t√≠ch so s√°nh:**")
        
        morph_comparison_df = pd.DataFrame({
            'C·∫•u h√¨nh': ['iter=1, k=3x3 (‚úì)', 'iter=2, k=3x3', 'iter=1, k=5x5', 'iter=2, k=5x5'],
            'K·∫øt n·ªëi n√©t': ['T·ªët', 'R·∫•t t·ªët', 'T·ªët', 'R·∫•t t·ªët'],
            'B·∫£o to√†n g√≥c': ['Xu·∫•t s·∫Øc (‚úì)', 'Trung b√¨nh', 'K√©m', 'R·∫•t k√©m'],
            'ƒê·ªô d√†y n√©t': ['V·ª´a ph·∫£i', 'D√†y', 'D√†y', 'R·∫•t d√†y'],
            'Ph√π h·ª£p': ['H√¨nh h·ªçc (g√≥c vu√¥ng, nh·ªçn)', 'Ch·ªØ s·ªë (curves)', 'Ch·ªØ c√°i l·ªõn', 'ƒê·ªëi t∆∞·ª£ng to, nhi·ªÖu m·∫°nh']
        })
        
        st.dataframe(morph_comparison_df, use_container_width=True, hide_index=True)
        
        st.success("**K·∫øt lu·∫≠n:** Ch·ªçn **iterations=1, kernel=3x3** cho h√¨nh h·ªçc ƒë·ªÉ b·∫£o to√†n g√≥c vu√¥ng (h√¨nh ch·ªØ nh·∫≠t) v√† g√≥c nh·ªçn (tam gi√°c). Iterations/kernel cao l√†m tr√≤n g√≥c ‚Üí nh·∫ßm l·∫´n gi·ªØa c√°c h√¨nh.")
        
    else:
        st.warning("Vui l√≤ng upload v√† nh·∫≠n d·∫°ng ·∫£nh ·ªü Tab 1 ƒë·ªÉ xem so s√°nh chi ti·∫øt")

# ==============================================================================
# FOOTER
# ==============================================================================

st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 20px;'>
    <h4>BTL X·ª≠ L√Ω ·∫¢nh - Nh·∫≠n D·∫°ng v·ªõi CNN & OpenCV</h4>
    <p style='margin: 10px 0; font-size: 14px;'>
        ·ª®ng d·ª•ng 10+ k·ªπ thu·∫≠t x·ª≠ l√Ω ·∫£nh: CLAHE, Adaptive Threshold, Morphology Operations,<br>
        Contour Detection, Distance Transform, Hu Moments, Center of Mass, CNN Feature Extraction
    </p>
</div>
""", unsafe_allow_html=True)
