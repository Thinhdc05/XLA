# ==============================================================================
# APP HO√ÄN CH·ªàNH - Nh·∫≠n d·∫°ng ch·ªØ s·ªë & h√¨nh h·ªçc v·ªõi X·ª¨ L√ù ·∫¢NH N√ÇNG CAO
# ƒê·∫ßy ƒë·ªß t√≠nh nƒÉng cho BTL X·ª≠ l√Ω ·∫¢nh
# ==============================================================================

import streamlit as st
import cv2
import numpy as np
from tensorflow.keras.models import load_model
from PIL import Image
import pandas as pd
import matplotlib.pyplot as plt

# Import modules
from config import (
    DIGITS_LABELS, SHAPES_LABELS, 
    MODEL_PATH_DIGITS, MODEL_PATH_SHAPES
)
from scipy.ndimage import center_of_mass

# Import advanced modules
from preprocessing.visualizer import visualize_pipeline, display_pipeline_streamlit
from preprocessing.advanced import (contour_shape_analysis, compute_hu_moments,
                                   edge_detection_comparison, threshold_comparison)
from model_analysis.feature_maps import (display_feature_maps_streamlit, 
                                        display_filters_streamlit,
                                        display_heatmap_streamlit)
from shape_detection.polygon_detector import hybrid_shape_detection

# Canvas import
from streamlit_drawable_canvas import st_canvas

# ==============================================================================
# CONFIG
# ==============================================================================

st.set_page_config(
    page_title="BTL X·ª≠ L√Ω ·∫¢nh - Nh·∫≠n D·∫°ng",
    page_icon="üî¨",
    layout="wide"
)

# Custom CSS
st.markdown("""
<style>
    .main .block-container {
        padding-top: 1rem;
        max-width: 1400px;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    .stTabs [data-baseweb="tab"] {
        padding: 12px 24px;
        background-color: #f0f2f6;
        border-radius: 8px 8px 0 0;
    }
    .stButton button {
        font-weight: 600;
    }
</style>
""", unsafe_allow_html=True)

# ==============================================================================
# PREPROCESSING FUNCTION
# ==============================================================================

def smart_preprocess(image, mode='digit'):
    """Preprocessing th√¥ng minh cho c·∫£ digit v√† shape"""
    img = np.array(image)
    
    if len(img.shape) == 3:
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    else:
        gray = img
    
    h, w = gray.shape
    
    # CLAHE
    clahe = cv2.createCLAHE(clipLimit=2.0 if mode == 'digit' else 3.0, 
                            tileGridSize=(8,8))
    enhanced = clahe.apply(gray)
    
    # Denoise
    if mode == 'shape':
        denoised = cv2.bilateralFilter(enhanced, 9, 75, 75)
    else:
        denoised = cv2.GaussianBlur(enhanced, (5, 5), 0)
    
    # Threshold
    blocksize = 11 if mode == 'digit' else 13
    c_value = 2 if mode == 'digit' else 3
    thresh = cv2.adaptiveThreshold(
        denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY_INV, blockSize=blocksize, C=c_value
    )
    
    # Morphology
    kernel_size = 3 if mode == 'digit' else 5
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)
    cleaned = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel, iterations=1)
    
    # Find contours
    contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if contours:
        largest = max(contours, key=cv2.contourArea)
        x, y, cw, ch = cv2.boundingRect(largest)
        padding = 15 if mode == 'digit' else 20
        x1 = max(0, x - padding)
        y1 = max(0, y - padding)
        x2 = min(w, x + cw + padding)
        y2 = min(h, y + ch + padding)
        cropped = cleaned[y1:y2, x1:x2]
    else:
        cropped = cleaned
    
    # Resize
    if cropped.size > 0 and cropped.shape[0] > 0 and cropped.shape[1] > 0:
        resized = cv2.resize(cropped, (20, 20), interpolation=cv2.INTER_AREA)
    else:
        resized = np.zeros((20, 20), dtype=np.uint8)
    
    # Pad
    padded = np.pad(resized, ((4,4),(4,4)), 'constant', constant_values=0)
    
    # Center
    if np.sum(padded) > 0:
        cy, cx = center_of_mass(padded)
        shiftx = int(np.round(14 - cx))
        shifty = int(np.round(14 - cy))
        M = np.float32([[1, 0, shiftx], [0, 1, shifty]])
        centered = cv2.warpAffine(padded, M, (28, 28))
    else:
        centered = padded
    
    normalized = centered.astype(np.float32) / 255.0
    
    return {
        'original': img,
        'gray': gray,
        'enhanced': enhanced,
        'thresh': thresh,
        'cleaned': cleaned,
        'cropped': cropped,
        'final': centered,
        'processed': normalized.reshape(1, 28, 28, 1)
    }

# ==============================================================================
# LOAD MODELS
# ==============================================================================

@st.cache_resource
def load_digit_model():
    try:
        model = load_model(MODEL_PATH_DIGITS)
        return model, True
    except Exception as e:
        return None, False

@st.cache_resource
def load_shape_model():
    try:
        model = load_model(MODEL_PATH_SHAPES)
        return model, True
    except Exception as e:
        return None, False

digit_model, DIGIT_MODEL_LOADED = load_digit_model()
shape_model, SHAPE_MODEL_LOADED = load_shape_model()

# ==============================================================================
# SESSION STATE
# ==============================================================================

if 'recognition_mode' not in st.session_state:
    st.session_state.recognition_mode = 'Nh·∫≠n d·∫°ng S·ªë'
if 'uploaded_files' not in st.session_state:
    st.session_state.uploaded_files = []
if 'last_results' not in st.session_state:
    st.session_state.last_results = []
if 'show_results' not in st.session_state:
    st.session_state.show_results = False
if 'current_image_for_analysis' not in st.session_state:
    st.session_state.current_image_for_analysis = None

# ==============================================================================
# HEADER
# ==============================================================================

st.markdown("""
<div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 24px; border-radius: 12px; margin-bottom: 20px;'>
    <h1 style='color: white; margin: 0; font-size: 32px;'>
        üî¨ BTL X·ª¨ L√ù ·∫¢NH - Nh·∫≠n D·∫°ng Ch·ªØ S·ªë & H√¨nh H·ªçc
    </h1>
    <p style='color: #f0f0f0; margin: 8px 0 0 0; font-size: 15px;'>
        ‚ú® Visualization Pipeline ‚Ä¢ Feature Maps ‚Ä¢ Shape Detection ‚Ä¢ Advanced CV Techniques
    </p>
</div>
""", unsafe_allow_html=True)

# ==============================================================================
# MAIN TABS
# ==============================================================================

tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "üéØ Nh·∫≠n D·∫°ng", 
    "üî¨ Pipeline X·ª≠ L√Ω ·∫¢nh",
    "üß† Feature Maps (CNN)",
    "üîç Shape Analysis (OpenCV)",
    "üìö K·ªπ Thu·∫≠t N√¢ng Cao"
])

# ==============================================================================
# TAB 1: NH·∫¨N D·∫†NG
# ==============================================================================

with tab1:
    st.markdown("### üéØ Nh·∫≠n D·∫°ng - 2 Ch·∫ø ƒê·ªô Chuy√™n Bi·ªát")
    
    # Mode selection
    col_m1, col_m2 = st.columns(2)
    with col_m1:
        if st.button("üî¢ Nh·∫≠n d·∫°ng S·ªê (0-9)", 
                     type="primary" if st.session_state.recognition_mode == 'Nh·∫≠n d·∫°ng S·ªë' else "secondary",
                     use_container_width=True):
            st.session_state.recognition_mode = 'Nh·∫≠n d·∫°ng S·ªë'
            st.rerun()
    
    with col_m2:
        if st.button("üî∫ Nh·∫≠n d·∫°ng H√åNH H·ªåC", 
                     type="primary" if st.session_state.recognition_mode == 'Nh·∫≠n d·∫°ng H√¨nh h·ªçc' else "secondary",
                     use_container_width=True):
            st.session_state.recognition_mode = 'Nh·∫≠n d·∫°ng H√¨nh h·ªçc'
            st.rerun()
    
    # Display mode
    if st.session_state.recognition_mode == 'Nh·∫≠n d·∫°ng S·ªë':
        st.info("üî¢ **Ch·∫ø ƒë·ªô:** Nh·∫≠n d·∫°ng s·ªë 0-9 | Model chuy√™n bi·ªát cho digits")
        current_model = digit_model
        model_loaded = DIGIT_MODEL_LOADED
        current_labels = DIGITS_LABELS
        preprocess_mode = 'digit'
    else:
        st.info("üî∫ **Ch·∫ø ƒë·ªô:** Nh·∫≠n d·∫°ng h√¨nh h·ªçc (Tr√≤n/HCN/Tam gi√°c) | Model chuy√™n bi·ªát cho shapes")
        current_model = shape_model
        model_loaded = SHAPE_MODEL_LOADED
        current_labels = SHAPES_LABELS
        preprocess_mode = 'shape'
    
    st.markdown("---")
    
    # Input method selection
    st.markdown("### üìù C√°ch Nh·∫≠p ·∫¢nh")
    input_method = st.radio(
        "Ch·ªçn c√°ch nh·∫≠p:",
        ["üì§ Upload ·∫£nh t·ª´ m√°y", "‚úèÔ∏è V·∫Ω tr·ª±c ti·∫øp"],
        horizontal=True
    )
    
    uploaded_file = None
    canvas_result = None
    
    if input_method == "üì§ Upload ·∫£nh t·ª´ m√°y":
        uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh ƒë·ªÉ nh·∫≠n d·∫°ng", type=['png', 'jpg', 'jpeg'])
    else:
        st.markdown("**‚úèÔ∏è V·∫Ω s·ªë ho·∫∑c h√¨nh b√™n d∆∞·ªõi:**")
        
        # Ch·ªçn m√†u b√∫t (m·∫∑c ƒë·ªãnh ƒë·ªè ƒë·ªÉ th·ªÉ hi·ªán b∆∞·ªõc Grayscale trong pipeline)
        col_color1, col_color2, col_color3 = st.columns([1, 1, 2])
        with col_color1:
            stroke_color = st.color_picker("üé® M√†u b√∫t:", "#FF0000", key="stroke_color")
        with col_color2:
            stroke_width = st.slider("‚úèÔ∏è ƒê·ªô d√†y:", 5, 30, 15, key="stroke_width")
        
        col_canvas1, col_canvas2 = st.columns([2, 1])
        
        with col_canvas1:
            # Drawing canvas
            canvas_result = st_canvas(
                fill_color="rgba(0, 0, 0, 0)",
                stroke_width=stroke_width,
                stroke_color=stroke_color,
                background_color="#000000",
                height=280,
                width=280,
                drawing_mode="freedraw",
                key="canvas",
            )
        
        with col_canvas2:
            st.markdown("**üí° H∆∞·ªõng d·∫´n:**")
            if st.session_state.recognition_mode == 'Nh·∫≠n d·∫°ng S·ªë':
                st.write("‚Ä¢ V·∫Ω ch·ªØ s·ªë 0-9")
                st.write("‚Ä¢ V·∫Ω ƒë·ªß l·ªõn, n√©t r√µ")
                st.warning("‚ö†Ô∏è **V·∫Ω th·∫≥ng ƒë·ª©ng!**\nS·ªë xoay nghi√™ng >20¬∞ s·∫Ω nh·∫≠n sai")
            else:
                st.write("‚Ä¢ V·∫Ω h√¨nh tr√≤n")
                st.write("‚Ä¢ V·∫Ω h√¨nh ch·ªØ nh·∫≠t")
                st.write("‚Ä¢ V·∫Ω tam gi√°c")
                st.info("‚úÖ H√¨nh xoay b·∫•t k·ª≥ g√≥c ƒë·ªô ƒë·ªÅu OK")
            
            if st.button("üóëÔ∏è X√≥a canvas", use_container_width=True):
                st.rerun()
    
    # Process input
    image = None
    
    if input_method == "üì§ Upload ·∫£nh t·ª´ m√°y" and uploaded_file:
        image = Image.open(uploaded_file)
    elif input_method == "‚úèÔ∏è V·∫Ω tr·ª±c ti·∫øp" and canvas_result.image_data is not None:
        # Convert canvas to PIL Image (extract RGB, not alpha)
        canvas_data = canvas_result.image_data
        if np.sum(canvas_data) > 0:  # Check if drawn
            # Get RGB channels (colored strokes on black background)
            rgb_image = canvas_data[:, :, :3]
            
            # Store original RGB for display
            st.session_state['canvas_rgb'] = rgb_image.copy()
            
            # Convert to grayscale (this is the preprocessing step!)
            gray_canvas = cv2.cvtColor(rgb_image.astype('uint8'), cv2.COLOR_RGB2GRAY)
            
            # Store grayscale for display
            st.session_state['canvas_gray'] = gray_canvas.copy()
            
            # Create PIL Image
            image = Image.fromarray(gray_canvas)
    
    if image:
        
        col1, col2, col3 = st.columns([1, 1, 1])
        
        with col1:
            # Hi·ªÉn th·ªã ·∫£nh RGB n·∫øu t·ª´ canvas, grayscale n·∫øu upload
            if input_method == "‚úèÔ∏è V·∫Ω tr·ª±c ti·∫øp" and 'canvas_rgb' in st.session_state:
                st.image(st.session_state['canvas_rgb'], caption="·∫¢nh g·ªëc (RGB)", use_container_width=True)
            else:
                st.image(image, caption="·∫¢nh g·ªëc", use_container_width=True, channels='GRAY')
        
        if st.button("‚ñ∂Ô∏è NH·∫¨N D·∫†NG", type="primary", use_container_width=True):
            if not model_loaded:
                st.error(f"‚úó Model ch∆∞a train! Ch·∫°y: `python train_{'digits' if preprocess_mode=='digit' else 'shapes'}.py`")
            else:
                with st.spinner("ƒêang x·ª≠ l√Ω..."):
                    # Preprocess
                    processed = smart_preprocess(image, mode=preprocess_mode)
                    
                    # Predict
                    predictions = current_model.predict(processed['processed'], verbose=0)
                    pred_class = np.argmax(predictions[0])
                    confidence = predictions[0][pred_class] * 100
                    
                    # Save for other tabs (with RGB original if from canvas)
                    original_for_display = image
                    if input_method == "‚úèÔ∏è V·∫Ω tr·ª±c ti·∫øp" and 'canvas_rgb' in st.session_state:
                        # Use RGB canvas for pipeline display
                        original_for_display = Image.fromarray(st.session_state['canvas_rgb'])
                    
                    st.session_state.current_image_for_analysis = {
                        'original': original_for_display,
                        'processed': processed,
                        'prediction': pred_class,
                        'confidence': confidence,
                        'all_probs': predictions[0],
                        'mode': preprocess_mode
                    }
                    
                    with col2:
                        st.image(processed['final'], caption="X·ª≠ l√Ω 28x28", use_container_width=True, channels='GRAY')
                    
                    with col3:
                        result_label = current_labels[pred_class]
                        color = '#4caf50' if confidence >= 90 else '#ff9800' if confidence >= 75 else '#f44336'
                        
                        st.markdown(f"""
                        <div style='background: {color}20; padding: 24px; border-radius: 12px; 
                                    border-left: 5px solid {color}; text-align: center;'>
                            <h2 style='color: {color}; margin: 0;'>{result_label}</h2>
                            <p style='color: {color}; font-size: 20px; margin: 10px 0 0 0;'>
                                Confidence: {confidence:.1f}%
                            </p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # Top predictions
                    st.markdown("#### üìä Top 3 Predictions")
                    top3_idx = np.argsort(predictions[0])[::-1][:3]
                    
                    cols = st.columns(3)
                    for i, idx in enumerate(top3_idx):
                        with cols[i]:
                            prob = predictions[0][idx] * 100
                            st.metric(
                                f"#{i+1}: {current_labels[idx]}", 
                                f"{prob:.1f}%",
                                delta=f"{'‚úì' if i == 0 else ''}"
                            )
                
                st.success("‚úÖ Nh·∫≠n d·∫°ng ho√†n t·∫•t! Xem c√°c tab kh√°c ƒë·ªÉ ph√¢n t√≠ch chi ti·∫øt.")

# ==============================================================================
# TAB 2: PIPELINE X·ª¨ L√ù ·∫¢NH
# ==============================================================================

with tab2:
    st.markdown("### üî¨ PIPELINE X·ª¨ L√ù ·∫¢NH - 10 B∆∞·ªõc Chi Ti·∫øt")
    
    st.info("üí° **Ch·ª©ng minh hi·ªÉu qu√° tr√¨nh x·ª≠ l√Ω ·∫£nh** - Y√™u c·∫ßu BTL")
    
    if st.session_state.current_image_for_analysis:
        data = st.session_state.current_image_for_analysis
        
        # Visualize full pipeline
        result = visualize_pipeline(data['original'], mode=data['mode'])
        display_pipeline_streamlit(result)
        
        # Additional analysis
        st.markdown("---")
        st.markdown("### üìä Ph√¢n T√≠ch Histogram")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Histogram ·∫¢nh G·ªëc**")
            gray_img = data['processed']['gray']
            fig1, ax1 = plt.subplots(figsize=(8, 4))
            ax1.hist(gray_img.ravel(), bins=256, range=[0, 256], color='blue', alpha=0.7)
            ax1.set_xlabel('Pixel Intensity')
            ax1.set_ylabel('Frequency')
            ax1.grid(alpha=0.3)
            st.pyplot(fig1)
        
        with col2:
            st.markdown("**Histogram Sau CLAHE**")
            enhanced_img = data['processed']['enhanced']
            fig2, ax2 = plt.subplots(figsize=(8, 4))
            ax2.hist(enhanced_img.ravel(), bins=256, range=[0, 256], color='green', alpha=0.7)
            ax2.set_xlabel('Pixel Intensity')
            ax2.set_ylabel('Frequency')
            ax2.grid(alpha=0.3)
            st.pyplot(fig2)
        
        st.caption("üìà CLAHE l√†m histogram ph√¢n b·ªë ƒë·ªÅu h∆°n ‚Üí TƒÉng contrast, d·ªÖ threshold")
        
    else:
        st.warning("‚ö†Ô∏è Vui l√≤ng upload v√† nh·∫≠n d·∫°ng ·∫£nh ·ªü Tab 1 tr∆∞·ªõc!")

# ==============================================================================
# TAB 3: FEATURE MAPS
# ==============================================================================

with tab3:
    st.markdown("### üß† FEATURE MAPS - CNN H·ªçc G√¨ T·ª´ ·∫¢nh?")
    
    st.info("üí° **Ch·ª©ng minh hi·ªÉu tr√≠ch ch·ªçn ƒë·∫∑c tr∆∞ng** - Y√™u c·∫ßu BTL")
    
    if st.session_state.current_image_for_analysis:
        data = st.session_state.current_image_for_analysis
        model = digit_model if data['mode'] == 'digit' else shape_model
        
        if model:
            # Feature Maps
            st.markdown("#### üé® Activation Maps - Output c·ªßa t·ª´ng Conv Layer")
            display_feature_maps_streamlit(model, data['processed']['processed'], max_per_layer=8)
            
            st.markdown("---")
            
            # Filters
            st.markdown("#### üîç Filters/Kernels - B·ªô l·ªçc CNN h·ªçc ƒë∆∞·ª£c")
            display_filters_streamlit(model, max_per_layer=16)
            
            st.markdown("---")
            
            # Heatmap
            st.markdown("#### üî• Attention Heatmap - V√πng Model Ch√∫ √ù")
            display_heatmap_streamlit(
                model, 
                data['processed']['processed'],
                data['prediction'],
                data['processed']['final']
            )
        else:
            st.error("Model ch∆∞a load!")
    else:
        st.warning("‚ö†Ô∏è Vui l√≤ng upload v√† nh·∫≠n d·∫°ng ·∫£nh ·ªü Tab 1 tr∆∞·ªõc!")

# ==============================================================================
# TAB 4: SHAPE ANALYSIS
# ==============================================================================

with tab4:
    st.markdown("### üîç SHAPE ANALYSIS - Ph√°t Hi·ªán H√¨nh H·ªçc v·ªõi OpenCV")
    
    st.info("üí° **Ph√°t hi·ªán h√¨nh h·ªçc c∆° b·∫£n** - Y√™u c·∫ßu BTL")
    
    if st.session_state.current_image_for_analysis:
        data = st.session_state.current_image_for_analysis
        
        # Hybrid detection
        st.markdown("#### üéØ Ph√°t Hi·ªán T·ª± ƒê·ªông (Hybrid Method)")
        
        gray_img = data['processed']['gray']
        result = hybrid_shape_detection(gray_img)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.image(gray_img, caption="·∫¢nh g·ªëc (grayscale)", use_container_width=True, channels='GRAY')
        
        with col2:
            if result['visualization'] is not None:
                st.image(result['visualization'], caption="Ph√°t hi·ªán shape", use_container_width=True, channels='RGB')
        
        # Summary
        st.markdown("#### üìä K·∫øt Qu·∫£ Ph√°t Hi·ªán")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Dominant Shape", result['dominant_shape'])
        with col2:
            st.metric("Circles", result['summary']['n_circles'])
        with col3:
            st.metric("Rectangles", result['summary']['n_rectangles'])
        with col4:
            st.metric("Triangles", result['summary']['n_triangles'])
        
        # Detailed analysis
        st.markdown("---")
        st.markdown("#### üî¨ Ph√¢n T√≠ch Chi Ti·∫øt Contour")
        
        analysis = contour_shape_analysis(gray_img)
        
        if analysis:
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Area", f"{analysis['area']:.0f} px¬≤")
                st.metric("Perimeter", f"{analysis['perimeter']:.0f} px")
            
            with col2:
                st.metric("Circularity", f"{analysis['circularity']:.3f}")
                st.metric("Solidity", f"{analysis['solidity']:.3f}")
            
            with col3:
                st.metric("Aspect Ratio", f"{analysis['aspect_ratio']:.2f}")
                st.metric("Vertices", analysis['num_vertices'])
            
            st.success(f"üéØ **K·∫øt lu·∫≠n:** {analysis['shape_type']}")
            
            # Hu Moments
            st.markdown("#### üßÆ Hu Moments (ƒê·∫∑c tr∆∞ng b·∫•t bi·∫øn)")
            hu = compute_hu_moments(gray_img)
            
            hu_df = pd.DataFrame({
                'Moment': [f'Hu[{i}]' for i in range(7)],
                'Value': [f"{val:.4f}" for val in hu]
            })
            
            st.dataframe(hu_df, use_container_width=True, hide_index=True)
            st.caption("üìå Hu Moments b·∫•t bi·∫øn v·ªõi translation, rotation, scale - D√πng ƒë·ªÉ nh·∫≠n d·∫°ng shape")
        
    else:
        st.warning("‚ö†Ô∏è Vui l√≤ng upload v√† nh·∫≠n d·∫°ng ·∫£nh ·ªü Tab 1 tr∆∞·ªõc!")

# ==============================================================================
# TAB 5: K·ª∏ THU·∫¨T N√ÇNG CAO
# ==============================================================================

with tab5:
    st.markdown("### üìö C√ÅC K·ª∏ THU·∫¨T X·ª¨ L√ù ·∫¢NH N√ÇNG CAO")
    
    st.info("üí° **√Åp d·ª•ng nhi·ªÅu k·ªπ thu·∫≠t x·ª≠ l√Ω ·∫£nh** - Th·ªÉ hi·ªán hi·ªÉu bi·∫øt s√¢u")
    
    if st.session_state.current_image_for_analysis:
        data = st.session_state.current_image_for_analysis
        gray_img = data['processed']['gray']
        
        # Edge Detection
        st.markdown("#### üî≤ Edge Detection - So S√°nh C√°c Ph∆∞∆°ng Ph√°p")
        
        edges = edge_detection_comparison(gray_img)
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.image(edges['sobel'], caption="Sobel", use_container_width=True, channels='GRAY')
        with col2:
            st.image(edges['canny'], caption="Canny", use_container_width=True, channels='GRAY')
        with col3:
            st.image(edges['laplacian'], caption="Laplacian", use_container_width=True, channels='GRAY')
        with col4:
            st.image(edges['scharr'], caption="Scharr", use_container_width=True, channels='GRAY')
        
        st.caption("üìä **Sobel**: Gradient (X+Y) | **Canny**: 2-threshold edge | **Laplacian**: 2nd derivative | **Scharr**: Improved Sobel")
        
        # Threshold Comparison
        st.markdown("---")
        st.markdown("#### üéöÔ∏è Threshold - So S√°nh C√°c Ph∆∞∆°ng Ph√°p")
        
        thresholds = threshold_comparison(gray_img)
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.image(thresholds['otsu'], caption="Otsu (Global)", use_container_width=True, channels='GRAY')
        with col2:
            st.image(thresholds['adaptive_mean'], caption="Adaptive Mean", use_container_width=True, channels='GRAY')
        with col3:
            st.image(thresholds['adaptive_gaussian'], caption="Adaptive Gaussian", use_container_width=True, channels='GRAY')
        with col4:
            st.image(thresholds['binary_fixed'], caption="Binary Fixed", use_container_width=True, channels='GRAY')
        
        st.caption("üìä **Adaptive** threshold t·ªët h∆°n cho ·∫£nh √°nh s√°ng kh√¥ng ƒë·ªÅu")
        
        # Summary
        st.markdown("---")
        st.markdown("### ‚úÖ T·ªïng K·∫øt K·ªπ Thu·∫≠t ƒê√£ √Åp D·ª•ng")
        
        techniques = {
            'K·ªπ Thu·∫≠t': [
                'CLAHE', 'Gaussian/Bilateral Filter', 'Adaptive Threshold',
                'Morphology (Opening/Closing)', 'Contour Detection', 'Distance Transform',
                'Hu Moments', 'Edge Detection (Sobel/Canny/Laplacian)',
                'Hough Transform', 'Bounding Box & Crop', 'Center of Mass', 'CNN Feature Maps'
            ],
            'M·ª•c ƒê√≠ch': [
                'TƒÉng contrast c·ª•c b·ªô',
                'Kh·ª≠ nhi·ªÖu, gi·ªØ edge',
                'Chuy·ªÉn binary t·ª± ƒë·ªông',
                'L√†m s·∫°ch, k·∫øt n·ªëi contour',
                'T√¨m bi√™n ƒë·ªëi t∆∞·ª£ng',
                'Ph√¢n t√≠ch ƒë·ªô d√†y',
                'ƒê·∫∑c tr∆∞ng b·∫•t bi·∫øn',
                'Ph√°t hi·ªán bi√™n',
                'Ph√°t hi·ªán h√¨nh tr√≤n',
                'Tr√≠ch xu·∫•t ƒë·ªëi t∆∞·ª£ng',
                'CƒÉn gi·ªØa ·∫£nh',
                'Tr√≠ch ch·ªçn ƒë·∫∑c tr∆∞ng CNN'
            ]
        }
        
        st.dataframe(techniques, use_container_width=True, hide_index=True)
        
    else:
        st.warning("‚ö†Ô∏è Vui l√≤ng upload v√† nh·∫≠n d·∫°ng ·∫£nh ·ªü Tab 1 tr∆∞·ªõc!")

# ==============================================================================
# FOOTER
# ==============================================================================

st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 20px;'>
    <h4>üî¨ BTL X·ª≠ L√Ω ·∫¢nh - Nh·∫≠n D·∫°ng v·ªõi CNN & OpenCV</h4>
    <p style='margin: 10px 0;'>
        ‚úÖ 2 Models Chuy√™n Bi·ªát ‚Ä¢ üî¨ Visualization Pipeline ‚Ä¢ üß† Feature Maps ‚Ä¢ üîç Shape Detection<br>
        üìä 10+ K·ªπ Thu·∫≠t X·ª≠ L√Ω ·∫¢nh ‚Ä¢ üéØ Evaluation Dashboard ‚Ä¢ üìö Documented Code
    </p>
    <p style='font-size: 12px; color: #999;'>
        √Åp d·ª•ng: CLAHE, Adaptive Threshold, Morphology, Contour Analysis, Hu Moments,<br>
        Edge Detection, Hough Transform, Distance Transform, CNN Visualization
    </p>
</div>
""", unsafe_allow_html=True)
